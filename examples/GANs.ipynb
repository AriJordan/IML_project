{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Code source: Sebastian Curi and Andreas Krause, based on Jaques Grobler (sklearn demos).\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# We start importing some modules and running some magic commands\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# General math and plotting modules.\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import erfinv\n",
    "from scipy import linalg\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "\n",
    "# Project files.\n",
    "from utilities.util import gradient_descent\n",
    "from utilities.classifiers import Logistic\n",
    "from utilities.regularizers import L2Regularizer\n",
    "from utilities.load_data import polynomial_data, linear_separable_data\n",
    "from utilities import plot_helpers\n",
    "from utilities.widgets import noise_widget, n_components_widget, min_prob_widget\n",
    "\n",
    "# Widget and formatting modules\n",
    "import IPython\n",
    "import ipywidgets\n",
    "from ipywidgets import interact, interactive, interact_manual, fixed\n",
    "from matplotlib import rcParams\n",
    "import matplotlib as mpl \n",
    "\n",
    "# If in your browser the figures are not nicely vizualized, change the following line. \n",
    "rcParams['figure.figsize'] = (10, 5)\n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "# Machine Learning library. \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM(object):\n",
    "    def __init__(self, weights, means, scales):\n",
    "        self.num_centers = len(weights)\n",
    "        self.weights = weights / np.sum(weights)\n",
    "        self.means = means\n",
    "        self.scales = scales \n",
    "    \n",
    "    def sample(self, batch_size=1):\n",
    "        centers = np.random.choice(self.num_centers, batch_size, p=self.weights)\n",
    "        eps = np.random.randn(batch_size)\n",
    "        return self.means[centers] + eps * self.scales[centers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gmm(true_model, sampling_model,  title):\n",
    "    gaussians = [norm(mean, scale) for mean, scale in zip(true_model.means, true_model.scales)]\n",
    "    scale = sum(true_model.weights)\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    X = np.linspace(-1.25, 1.25, 1000)\n",
    "    y = np.zeros_like(X)\n",
    "    for i, (weight, gaussian) in enumerate(zip(true_model.weights, gaussians)):\n",
    "        y += weight * gaussian.pdf(X) / scale\n",
    "\n",
    "    ax.plot(X, y, label='Exact PDF')\n",
    "    \n",
    "    ax.hist(sampling_model.sample(10000), bins=100, density=True, label='Samples')\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_xlim([-1.25, 1.25])\n",
    "    ax.set_title(title)\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    IPython.display.display(fig)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Given a random input, produce a random output.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int, output_dim: int, noise='uniform'):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.noise = noise\n",
    "        print(noise)\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, 15),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(15, output_dim),\n",
    "            nn.Tanh()  # Distribution is bounded between -1 and 1.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "    def rsample(self, batch_size=1):\n",
    "        \"\"\"Get a differentiable sample of the generator model.\"\"\"\n",
    "        if self.noise == 'uniform':\n",
    "            noise = torch.rand(batch_size, self.input_dim)\n",
    "\n",
    "        elif self.noise == 'normal':\n",
    "            noise = torch.randn(batch_size, self.input_dim)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        return self(noise).squeeze(-1)\n",
    "\n",
    "    def sample(self, batch_size=1):\n",
    "        \"\"\"Get a sample of the generator model.\"\"\"\n",
    "        return self.rsample(batch_size).detach()\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminate if true from fake samples.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, 25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(25, 1),\n",
    "            nn.Sigmoid()  # Output is bounded between 0 and 1.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, true_model, generator_optimizer, discriminator_optimizer, \n",
    "              num_iter, discriminator_loss, generator_loss, batch_size=64):\n",
    "    loss = nn.BCELoss()\n",
    "    for i in range(num_iter):\n",
    "        true_data = torch.tensor(true_model.sample(batch_size)).float().unsqueeze(-1)\n",
    "        fake_data = generator.rsample(batch_size).unsqueeze(-1)\n",
    "        # equivalently, fake_data = generator(torch.randn(batch_size, code_size)).squeeze()\n",
    "\n",
    "        true_label = torch.full((batch_size,), 1.)\n",
    "        fake_label = torch.full((batch_size,), 0.)\n",
    "\n",
    "        ###################################################################################\n",
    "        # Update G network: maximize log(D(G(z)))                                         #\n",
    "        ###################################################################################\n",
    "        generator_optimizer.zero_grad()\n",
    "        loss_g = loss(discriminator(fake_data).squeeze(-1), true_label)  # true label.\n",
    "        loss_g.backward()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        generator_loss.append(loss_g.item())\n",
    "\n",
    "        ###################################################################################\n",
    "        # Update D network: maximize log(D(x)) + log(1 - D(G(z)))                         #\n",
    "        ###################################################################################\n",
    "        discriminator_optimizer.zero_grad()\n",
    "\n",
    "        # train on true data.\n",
    "        loss_d_true = loss(discriminator(true_data).squeeze(-1), true_label)\n",
    "        loss_d_true.backward()\n",
    "\n",
    "        # train on fake data.\n",
    "        loss_d_fake = loss(discriminator(fake_data.detach()).squeeze(-1), fake_label)\n",
    "        loss_d_fake.backward()\n",
    "\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        loss_d = loss_d_true + loss_d_fake\n",
    "        discriminator_loss.append(loss_d.item())\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            ax = plot_gmm(true_model, generator, f\"Episode {i}\")\n",
    "    \n",
    "    return discriminator_loss, generator_loss\n",
    "\n",
    "\n",
    "def train_gan_interactive(num_iter, true_model, noise_model, noise_dim, generator_lr, discriminator_lr):\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    generator = Generator(input_dim=noise_dim, output_dim=1, noise=noise_model)\n",
    "    discriminator = Discriminator(input_dim=1)\n",
    "    \n",
    "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=generator_lr, betas=(0.5, 0.999))\n",
    "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=discriminator_lr, betas=(0.5, 0.99))\n",
    "\n",
    "    discriminator_loss, generator_loss = [], []\n",
    "    try:\n",
    "        train_gan(generator, discriminator, true_model, generator_optimizer, discriminator_optimizer, num_iter, discriminator_loss, generator_loss)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    plot_gmm(true_model, generator, \"Final Generator Model\")\n",
    "    plt.plot(generator_loss, label='Generator Loss')\n",
    "    plt.plot(discriminator_loss, label='Discriminator Loss')\n",
    "    plt.xlabel('Iteration Number')\n",
    "    plt.ylabel(' Loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN's for fitting a Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 8)\n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "gaussian_model = GMM(weights=np.array([1.]),means=np.array([0.5]), scales=np.array([0.2])) \n",
    "plot_gmm(gaussian_model, gaussian_model, 'Exact Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 8)\n",
    "rcParams['font.size'] = 16\n",
    "num_iter = 15000\n",
    "interact_manual(lambda noise_model, noise_dim, generator_lr, discriminator_lr: train_gan_interactive(\n",
    "    num_iter, gaussian_model, noise_model, noise_dim, generator_lr, discriminator_lr),\n",
    "                noise_model=ipywidgets.Dropdown(options=['uniform', 'normal'], value='normal', description='Noise model:', style={'description_width': 'initial'}, continuous_update=False),\n",
    "                noise_dim=ipywidgets.IntSlider(min=1, max=10, value=4, description='Noise dimension:', style={'description_width': 'initial'}, continuous_update=False),\n",
    "                generator_lr=ipywidgets.FloatLogSlider(value=1e-4, min=-6, max=0, description=\"Generator lr\", style={'description_width': 'initial'}, continuous_update=False),\n",
    "                discriminator_lr=ipywidgets.FloatLogSlider(value=1e-4, min=-6, max=0, description=\"Discriminator lr\", style={'description_width': 'initial'}, continuous_update=False),\n",
    "               );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN's for fitting a GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 8)\n",
    "rcParams['font.size'] = 16\n",
    "\n",
    "gmm_model = GMM(weights=np.array([0.3, 0.5, 0.2]),\n",
    "                 means=np.array([-3., 0., 2.]) / 5,\n",
    "                 scales=np.array([0.5, 1.0, 0.1]) / 5)\n",
    "plot_gmm(gmm_model, gmm_model, 'Exact Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (20, 8)\n",
    "rcParams['font.size'] = 16\n",
    "num_iter = 15000\n",
    "interact_manual(lambda noise_model, noise_dim, generator_lr, discriminator_lr: train_gan_interactive(\n",
    "    num_iter, gmm_model, noise_model, noise_dim, generator_lr, discriminator_lr),\n",
    "                noise_model=ipywidgets.Dropdown(options=['uniform', 'normal'], value='normal', description='Noise model:', style={'description_width': 'initial'}, continuous_update=False),\n",
    "                noise_dim=ipywidgets.IntSlider(min=1, max=10, value=8, description='Noise dimension:', style={'description_width': 'initial'}, continuous_update=False),\n",
    "                generator_lr=ipywidgets.FloatLogSlider(value=5e-4, min=-6, max=0, description=\"Generator lr\", style={'description_width': 'initial'}, continuous_update=False),\n",
    "                discriminator_lr=ipywidgets.FloatLogSlider(value=1e-3, min=-6, max=0, description=\"Discriminator lr\", style={'description_width': 'initial'}, continuous_update=False),\n",
    "               );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
